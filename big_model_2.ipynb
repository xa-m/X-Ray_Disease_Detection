{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "\n",
    "# get the directory of the current file\n",
    "current_dir_win = os.path.dirname(os.path.realpath('__file__'))\n",
    "current_dir_linux = current_dir_win.replace('\\\\', '/')\n",
    "\n",
    "# print how many gpu's are available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_images(target_dir, num_images=4):\n",
    "    target_folder = target_dir\n",
    "    random_images = random.sample(os.listdir(target_folder), 4)\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 10))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(random_images, axes):\n",
    "        img = mpimg.imread(target_folder + \"/\" + img)\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_checkpoint(model_name, save_path=\"/models/checkpoint_models\"):\n",
    "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name), # create filepath to save model\n",
    "                                            verbose=0, # only output a limited amount of text\n",
    "                                            save_best_only=True) # save only the best model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111863"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = pd.read_csv(f\"{current_dir_linux}/data/train_df.csv\")\n",
    "\n",
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cardiomegaly', 'Emphysema', 'Effusion', 'No Finding', 'Hernia',\n",
       "       'Infiltration', 'Mass', 'Nodule', 'Atelectasis', 'Pneumothorax',\n",
       "       'Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema',\n",
       "       'Consolidation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all column names of all_labels drop: \"Image Index\", \"Patient ID\", \"FilePath\"\n",
    "label_names = all_labels.columns.drop([\"Image Index\", \"Patient ID\", \"FilePath\"])\n",
    "\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>FilePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_001/images/00000001_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_001/images/00000001_001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_001/images/00000001_002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_001/images/00000002_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_001/images/00000003_000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index  Patient ID  Cardiomegaly  Emphysema  Effusion  \\\n",
       "0  00000001_000.png           1             1          0         0   \n",
       "1  00000001_001.png           1             1          1         0   \n",
       "2  00000001_002.png           1             1          0         1   \n",
       "3  00000002_000.png           2             0          0         0   \n",
       "4  00000003_000.png           3             0          0         0   \n",
       "\n",
       "   No Finding  Hernia  Infiltration  Mass  Nodule  Atelectasis  Pneumothorax  \\\n",
       "0           0       0             0     0       0            0             0   \n",
       "1           0       0             0     0       0            0             0   \n",
       "2           0       0             0     0       0            0             0   \n",
       "3           1       0             0     0       0            0             0   \n",
       "4           0       1             0     0       0            0             0   \n",
       "\n",
       "   Pleural_Thickening  Pneumonia  Fibrosis  Edema  Consolidation  \\\n",
       "0                   0          0         0      0              0   \n",
       "1                   0          0         0      0              0   \n",
       "2                   0          0         0      0              0   \n",
       "3                   0          0         0      0              0   \n",
       "4                   0          0         0      0              0   \n",
       "\n",
       "                                           FilePath  \n",
       "0  ../input/data/images_001/images/00000001_000.png  \n",
       "1  ../input/data/images_001/images/00000001_001.png  \n",
       "2  ../input/data/images_001/images/00000001_002.png  \n",
       "3  ../input/data/images_001/images/00000002_000.png  \n",
       "4  ../input/data/images_001/images/00000003_000.png  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/data/images_001/images/00000001_000.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[\"FilePath\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path_to_labels(labels_all):\n",
    "    all_labels_w_path = labels_all.copy()\n",
    "    # loop through all labels filepaths and delete first 8 characters and replace them with current_dir_linux\n",
    "    for i in range(len(all_labels_w_path)):\n",
    "        all_labels_w_path[\"FilePath\"][i] = current_dir_linux + all_labels_w_path[\"FilePath\"][i][8:]\n",
    "    return all_labels_w_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_15332\\289152386.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_labels_w_path[\"FilePath\"][i] = current_dir_linux + all_labels_w_path[\"FilePath\"][i][8:]\n"
     ]
    }
   ],
   "source": [
    "all_labels_w_path = add_path_to_labels(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:/Programming/Machine_Learning/Xray_Detection/data/images_001/images/00000001_000.png'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels_w_path.iloc[0][\"FilePath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split with random state 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_labels, test_labels = train_test_split(all_labels_w_path, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89490, 22373)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels), len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a data loader (preparing the data for the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 89490 validated image filenames.\n",
      "Found 22373 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,samplewise_center=True, samplewise_std_normalization= True)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, samplewise_center=True, samplewise_std_normalization= True)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = train_labels,\n",
    "    directory=None,\n",
    "    x_col=\"FilePath\",\n",
    "    y_col=label_names,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_labels,\n",
    "    directory=None,\n",
    "    x_col=\"FilePath\",\n",
    "    y_col=label_names,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model 1: Just a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "\n",
    "base_mobilenet_model = MobileNet(input_shape =  (224, 224, 3), \n",
    "                                include_top = False,\n",
    "                                weights = None)\n",
    "\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    base_mobilenet_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(15, activation=\"sigmoid\")\n",
    "], name=\"model_001\")\n",
    "\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"binary_accuracy\", \"mae\"])\n",
    "\n",
    "model_1.fit(train_generator,\n",
    "            epochs=10,\n",
    "            steps_per_epoch=len(train_generator),\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=len(test_generator),\n",
    "            callbacks=[create_model_checkpoint(model_name=\"model_1_10_epoch_001\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: H:/Programming/Machine_Learning/Xray_Detection/models/saved_models/model_001\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: H:/Programming/Machine_Learning/Xray_Detection/models/saved_models/model_001\\assets\n"
     ]
    }
   ],
   "source": [
    "save_as = \"model_1_002.h5\"\n",
    "model_1.save(f\"{current_dir_linux}/models/saved_models/{save_as}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.models.load_model(f\"{current_dir_linux}/models/saved_models/{model_1.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
